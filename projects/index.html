<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Imadlab | Data Engineer & AI/ML Portfolio</title>
    <meta name="description" content="Explore Imad Eddine El Mouss's portfolio showcasing data engineering, AI/ML projects, blog posts, and software engineering work." />
    <meta name="author" content="Imad" />
    <meta name="keywords" content="imadlab, imad lab, imad, imad eddine, imad eddine elmouss, imad portfolio, imad data engineer, imad ai, imad machine learning, imad blog, imad data science, imadlab.me, imad Eddine El mouss, data engineer portfolio, ai portfolio, machine learning portfolio, elmouss, imad elmouss, imad eddine portfolio, imad eddine data engineer, imad eddine ai, imad eddine machine learning, imad eddine blog, imad eddine data science, imad eddine elmouss portfolio, imad eddine elmouss data engineer, imad eddine elmouss ai, imad eddine elmouss machine learning, imad eddine elmouss blog, imad eddine elmouss data science, imad Eddine El mouss portfolio, imad Eddine El mouss data engineer, imad Eddine El mouss ai, imad Eddine El mouss machine learning, imad Eddine El mouss blog, imad Eddine El mouss data science" />
    <link rel="canonical" href="https://imadlab.me" />

    <!-- Open Graph Meta Tags -->
    <meta property="og:title" content="Imadlab | Data Engineer & AI/ML Portfolio" />
    <meta property="og:description" content="Explore Imad Eddine El Mouss's portfolio showcasing data engineering, AI/ML projects, blog posts, and software engineering work." />
    <meta property="og:type" content="website" />
    <meta property="og:image" content="https://imadlab.me/opengraph-image.png" />
    <meta property="og:url" content="https://imadlab.me" />

    <!-- Twitter Card Meta Tags -->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:site" content="@imadlab" />
    <meta name="twitter:creator" content="@imadlab" />
    <meta name="twitter:title" content="Imadlab | Data Engineer & AI/ML Portfolio" />
    <meta name="twitter:description" content="Explore Imad Eddine El Mouss's portfolio showcasing data engineering, AI/ML projects, blog posts, and software engineering work." />
    <meta name="twitter:image" content="https://imadlab.me/opengraph-image.png" />

    <!-- Favicon and Theme Color -->
    <link rel="icon" href="/favicon.ico" sizes="any">
    <link rel="apple-touch-icon" href="/apple-touch-icon.png">
    <meta name="theme-color" content="#000000" />

    <!-- Font Preconnect and Preload for Performance -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="preconnect" href="https://mpkgugcasxpanhrkpkhs.supabase.co" crossorigin>
    <link rel="alternate" type="application/rss+xml" title="Imadlab Blog RSS Feed" href="/feed.xml" />
    <link rel="alternate" type="application/feed+json" title="Imadlab Blog JSON Feed" href="/feed.json" />
    <meta name="referrer" content="strict-origin-when-cross-origin" />
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&family=JetBrains+Mono:wght@300;400;500;600;700&display=swap" rel="stylesheet">

    <!-- Structured Data -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "WebSite",
      "url": "https://imadlab.me",
      "name": "Imadlab",
      "description": "Portfolio and writing by Imad Eddine El Mouss covering data engineering, AI/ML, and software projects.",
      "publisher": {
        "@type": "Person",
        "name": "Imad Eddine El Mouss",
        "url": "https://imadlab.me/about",
        "sameAs": [
          "https://github.com/imaddde867",
          "https://www.linkedin.com/in/imad-eddine-e-986741262"
        ]
      },
      "potentialAction": {
        "@type": "SearchAction",
        "target": "https://duckduckgo.com/?q=site%3Aimadlab.me+{search_term_string}",
        "query-input": "required name=search_term_string"
      }
    }
    </script>
    <script type="module" crossorigin src="/assets/index-C2wzmnot.js"></script>
    <link rel="modulepreload" crossorigin href="/assets/vendor-BWaHT4c5.js">
    <link rel="stylesheet" crossorigin href="/assets/vendor-2KSn8t0Q.css">
    <link rel="stylesheet" crossorigin href="/assets/index-DLZMwz3-.css">
  </head>

  <body>
    <h1 style="position: absolute; width: 1px; height: 1px; padding: 0; margin: -1px; overflow: hidden; clip: rect(0, 0, 0, 0); border: 0;">Imadlab | Data Engineer & AI/ML Portfolio</h1>
    <div id="root">
<main data-prerender="true" class="prerender-shell">
  <h1 class="text-3xl font-bold mb-4">Projects</h1>
  <section class="prerender-grid">

    <article class="prerender-card">
      <h2 class="prerender-title">Spiral Untangler ANN</h2>
      <p class="prerender-tags">Tech: Python, NumPy, Neural Networks, Data Visualization</p>
      <p class="prerender-summary">Neural network from scratch that learns to classify intertwined spirals, exploring nonlinear classification.</p>
      <a href="/projects/3d321db4-bd68-42d1-beae-f456341eb76e" class="prerender-link">View project</a>
    </article>

    <article class="prerender-card">
      <h2 class="prerender-title">InfiniteChessAI : Self-Improving Chess Opponent </h2>
      <p class="prerender-tags">Tech: Swift, Python, Flask, SwiftUI, python-chess</p>
      <p class="prerender-summary">Building a SwiftUI mobile chess app that learns from my own games and grows alongside me.</p>
      <a href="/projects/674332e4-f4aa-48ef-9d51-e66ffd0b7f04" class="prerender-link">View project</a>
    </article>

    <article class="prerender-card">
      <h2 class="prerender-title">Explainium — Procedural Knowledge Extraction</h2>
      <p class="prerender-tags">Tech: Python, LLM, Mistral-7B, FastAPI, Streamlit</p>
      <p class="prerender-summary">Offline local LLM system that extracts granular procedural knowledge from technical, safety, compliance, and operational documents.</p>
      <a href="/projects/7db7d135-00fc-4ea5-a4a5-6188eb6cde46" class="prerender-link">View project</a>
    </article>

    <article class="prerender-card">
      <h2 class="prerender-title">Security in Federated Learning</h2>
      <p class="prerender-tags">Tech: Python, Federated Learning, Security, Encryption</p>
      <p class="prerender-summary">Benchmarking privacy-preserving FL on CIFAR‑100 with telemetry, attacks, and selective encryption.</p>
      <a href="/projects/6dd91268-b428-4803-9100-904bf51b895f" class="prerender-link">View project</a>
    </article>

    <article class="prerender-card">
      <h2 class="prerender-title">Bank Term Deposit Prediction with Neural Networks</h2>
      <p class="prerender-tags">Tech: Machine Learning, Deep Learning, TensorFlow, Binary Classification, Data Analysis</p>
      <p class="prerender-summary">A deep learning model to predict customer term deposit subscriptions using banking and economic data. Achieved 90% accuracy with strong AUC performance, addressing class imbalance and campaign optimization.</p>
      <a href="/projects/80b51708-efa4-4ab8-a97e-9a61ea3bdefc" class="prerender-link">View project</a>
    </article>

    <article class="prerender-card">
      <h2 class="prerender-title">imadlab.me - Personal Portfolio &amp; Technical Blog Platform</h2>
      <p class="prerender-tags">Tech: React, TypeScript, Tailwind CSS, Supabase, Vite</p>
      <p class="prerender-summary">A React-TypeScript portfolio website featuring real-time integrations, secure admin portal, and dynamic content management. Built with modern web technologies and optimized for performance, SEO, and user experience.</p>
      <a href="/projects/5cf746e6-934f-400d-b51b-62e0daa4a183" class="prerender-link">View project</a>
    </article>

    <article class="prerender-card">
      <h2 class="prerender-title">ClearBox - Secure Messaging Platform</h2>
      <p class="prerender-tags">Tech: React, FastAPI, PostgreSQL, MQTT, WebSockets</p>
      <p class="prerender-summary">ClearBox is a full-stack secure messaging platform featuring real-time encrypted communication, group chat, and GDPR compliance, built with FastAPI, React, and MQTT.</p>
      <a href="/projects/51d8de9b-5876-4eda-ac5b-3411814bda84" class="prerender-link">View project</a>
    </article>

    <article class="prerender-card">
      <h2 class="prerender-title">NAVICAST Maritime Intelligence</h2>
      <p class="prerender-tags">Tech: Python, FastAPI, PostgreSQL, Machine Learning, MQTT</p>
      <p class="prerender-summary">Real-time maritime traffic analysis and AI predictive routing</p>
      <a href="/projects/1139086b-79f9-44a0-8f81-145dcc137b74" class="prerender-link">View project</a>
    </article>

    <article class="prerender-card">
      <h2 class="prerender-title">Spotify AI Music Recommendation</h2>
      <p class="prerender-tags">Tech: Python, Machine Learning, Flask, Spotify API, PCA</p>
      <p class="prerender-summary">An AI music recommender using PCA, K-means clustering, and Spotify audio features, with a Flask API and modern frontend interface.</p>
      <a href="/projects/ea66518d-ced2-4d09-b84c-63f57eefd644" class="prerender-link">View project</a>
    </article>
  </section>
</main>
</div>
  <script>window.__PRERENDERED_DATA__ = window.__PRERENDERED_DATA__ || {}; window.__PRERENDERED_DATA__["projects"] = [{"id":"3d321db4-bd68-42d1-beae-f456341eb76e","title":"Spiral Untangler ANN","description":"Neural network from scratch that learns to classify intertwined spirals, exploring nonlinear classification.","full_description":"I set out to answer a simple but deceptively hard question: Can i build a neural network entirely from scratch to perform a task like untangling intertwined spirals for example? Then started with this Spiral Untangler experiment stripping away the usual frameworks, and forcing me to learn and understand every transformation the model applies to data that is topologically tricky.\n\n## What’s Working Today\n- **NumPy-only neural network core** with Xavier initialization, forward/backward propagation, and gradient descent updates that I can fully inspect.\n- **Spiral data generator** that creates easy, medium, and hard intertwined spirals so I can dial up complexity on demand.\n- **Visualization toolkit** for scatter plots, decision boundaries, and loss curves, making each training run an interactive investigation rather than a blind optimization.\n- **Training workflow** that tracks cost, measures accuracy (~58% on the easy configuration, ~50% on a hard setting), and highlights how shallow architectures struggle with these manifolds.\n\n## What I’m Building Next\n- Crafting an “Impossibility” dataset to see exactly where the current model breaks.\n- Layer-by-layer geometric visualizations and animated training runs to show the network’s internal warping of space over time.\n- Gradient flow diagnostics to spot vanishing/exploding regimes.\n- Experiments with wider and deeper architectures plus new, bespoke topological challenges that stress-test the inductive bias of simple networks.\n\n## Where It’s Going\nBy the end of this phase I’ll have a transparent playground for topology-aware learning: richer datasets, animated insights into how latent spaces evolve, and a suite of architectural baselines that either succeed - or fail loudly lol - at untangling spirals. The goal isn’t just a high accuracy number; it’s a learning notebook about what it takes for neural nets to navigate non-linear manifolds and where the boundaries of `shallow understanding` truly lie.","tech_tags":["Python","NumPy","Neural Networks","Data Visualization"],"created_at":"2025-10-30T05:38:37.266239+00:00"},{"id":"674332e4-f4aa-48ef-9d51-e66ffd0b7f04","title":"InfiniteChessAI : Self-Improving Chess Opponent ","description":"Building a SwiftUI mobile chess app that learns from my own games and grows alongside me.","full_description":"## Vision\n\nI set out to build an end-to-end chess experience that blends a polished SwiftUI client with a learning-first backend. The long-term goal is a self-improving engine that ingests my own Chess.com history, trains on that data, and challenges me in a native iOS app. InfiniteChessAI exists to explore that full loop: board UX, data collection, move prediction, and, eventually, reinforcement learning.\n\n## What’s Built So Far\n\n- **SwiftUI board ('ChessAI/')** – Native iOS front-end featuring legal move generation, SAN parsing, animated piece interactions, and a resilient AI integration that now surfaces server errors instead of executing impossible moves.\n- **Mock inference server ('server/mock_ai_server.py')** – A lightweight Flask API backed by 'python-chess' that returns random legal moves, letting the client exercise real HTTP flows while the true engine bakes.\n- **Data tooling ('scripts/generate_chess_sft_dataset.py')** – Reproducible pipeline that downloads Chess.com archives, normalizes SAN histories for either color, and emits JSONL pairs primed for supervised fine-tuning. The helper tests under 'tests/' lock down history alignment.\n- **Sample dataset ('sft_data.jsonl')** – Representative output from the pipeline, demonstrating the prompt/completion format that will feed the forthcoming models.\n- **Developer ergonomics** – Fresh docs in 'README.md', a 'requirements-dev.txt' for full Python tooling, and a living 'todo.md' that tracks the roadmap.\n\n## Progress Highlights\n\n- Hardened the SAN parser so black’s perspective lines up correctly and the UI refuses illegal captures.\n- Added pytest coverage to the dataset builder, catching regressions before they taint future fine-tuning runs.\n- Improved AI service telemetry: the app now displays connection health and error states, enabling faster iteration on the backend.\n- Documented the workflow end-to-end, making onboarding (and future automation) straightforward.\n\n## What’s Next\n\n1. **Engine upgrade** – Replace the mocked policy with a deterministic engine that understands castling, en passant, checks, and mates.\n2. **Ruleset completeness** – Extend the Swift rules layer to cover the remaining SAN edge cases and add checkmate/stalemate detection.\n3. **Training loop automation** – Schedule archive refreshes, version generated datasets/models, and stand up evaluation harnesses for regression testing.\n4. **Experience polish** – Layer in move annotations, game history, and richer feedback to make the app feel like a true chess companion.\n\nInfiniteChessAI is already validating the core idea: an opinionated chess stack that connects data to gameplay. The next milestones will graduate it from a prototype into a self-improving sparring partner. Stay tuned—the real engine is on the way.\n","tech_tags":["Swift","Python","Flask","SwiftUI","python-chess"],"created_at":"2025-10-30T05:37:33.083863+00:00"},{"id":"7db7d135-00fc-4ea5-a4a5-6188eb6cde46","title":"Explainium — Procedural Knowledge Extraction","description":"Offline local LLM system that extracts granular procedural knowledge from technical, safety, compliance, and operational documents.","full_description":"Explainium ingests multi-format documents (PDF, DOCX, PPT(X), images via OCR, spreadsheets, and audio via Whisper) and uses a local Mistral-7B model via llama-cpp to extract facts and procedural items, outputting JSON entities with confidence scores. The system includes FastAPI endpoints and a Streamlit UI, configurable chunking and generation parameters, and provides an architecture with API, processing pipeline, LLM engine, and logging.","tech_tags":["Python","LLM","Mistral-7B","FastAPI","Streamlit","llama.cpp"],"created_at":"2025-10-30T05:37:04.003039+00:00"},{"id":"6dd91268-b428-4803-9100-904bf51b895f","title":"Security in Federated Learning","description":"Benchmarking privacy-preserving FL on CIFAR‑100 with telemetry, attacks, and selective encryption.","full_description":"Privacy-preserving FL with CIFAR‑100, gradient telemetry, attack simulation, and selective encryption\n\n## TL;DR\n- Building a configurable FedAvg baseline on CIFAR‑100 with per‑client telemetry and artifact persistence to study privacy risks and mitigations in federated learning.\n- Current 10‑round run exposed a stability bug in server averaging (NaN losses from round ~4). Next, I’m fixing aggregation and adding safeguards (clipping, precision controls) before scaling experiments and resuming selective encryption and attack pipelines.\n- The work is inspired and guided by concepts from “Security and Privacy in Federated Learning” (threat models, inversion/membership attacks, DP, secure aggregation, homomorphic encryption).\n\n## Why This Matters\nFederated learning distributes model training to clients to keep raw data local, but model updates can still leak sensitive information through gradients or statistics. This project explores that privacy surface, measures leakage, and tests mitigations in realistic image tasks.\n\n## Goals\n- Establish a reproducible FL baseline with transparent telemetry on client updates and training dynamics.\n- Simulate representative attacks (e.g., gradient inversion–style similarity analysis) and quantify leakage.\n- Evaluate mitigations: gradient clipping, differential privacy (clip + noise), secure aggregation, and selective homomorphic encryption (TenSEAL) on critical layers.\n- Report trade‑offs: accuracy, convergence, runtime, and reconstruction quality (PSNR/SSIM).\n\n## What’s Built So Far\n- FedAvg simulation in a Jupyter workflow on CIFAR‑100 with non‑IID client splits (Dirichlet α=0.5) and CUDA support.\n  - Notebook: `src/fl_simulation/fed_avg.ipynb`\n  - Per‑client telemetry: gradient/per‑layer norms, loss traces, batch sizes, class histograms.\n  - Deterministic seeding and reusable CIFAR‑100 loaders.\n- Round artifacts persisted for post‑hoc analysis:\n  - Meta JSON: `src/fl_simulation/fedavg_metrics_{round}_meta.json`\n  - Tensors: `*_tensors.pt` holding raw gradients, deltas, and server aggregates.\n- Early attack/analysis pipeline for gradient similarity and risk classification:\n  - Metrics + helpers: `src/attacks/quality_metrics.py`\n  - Driver + visualization: `src/attacks/run_attacks.py` (writes to `reports/attacks/`).\n- Selective encryption scaffold for TenSEAL experiments: `src/encryption/selective_encrypt.py`.\n- Reports: baseline summary exports in `reports/FL_AVG.pdf` and `reports/FL_AVG.html`.\n\n## Current State\n- Completed a 10‑round FedAvg run with 20 clients (sample 5/round) on CIFAR‑100.\n- Training diverges from round ~4 (NaN loss, ~1% accuracy).\n- Root cause: server delta averaging was not dimension‑safe (e.g., relying on `Tensor.T` for high‑rank tensors), which mis‑aggregated updates. This matches warnings observed in the PyTorch path and is reflected in later round metrics (NaNs) in JSON artifacts like `src/fl_simulation/fedavg_metrics_04_meta.json`.\n- Artifacts contain rich telemetry per round for analysis and debugging.\n\n## What’s Next\n- Fix server aggregation\n  - Implement explicit, dimension‑safe weighted averaging for state_dict tensors (no `.T` on non‑2D tensors; use broadcasting/addition by matching shapes).\n  - Add unit‑level checks on layer shapes and numeric health (finite checks) before/after aggregation.\n- Stabilize training\n  - Gradient clipping on clients; consider mixed precision controls.\n  - Validate on ≥50 rounds under non‑IID splits with accuracy and loss targets.\n- Resume privacy mitigations\n  - Differential Privacy: clip + noise accounting baseline.\n  - Selective HE (TenSEAL): encrypt sensitive layers/parameters first; expand coverage progressively; measure runtime/accuracy cost.\n  - Secure aggregation: aggregate under secrecy assumptions; compare to DP/HE.\n- Expand attacks and evaluation\n  - Implement reconstruction/membership‑style probes; extend gradient similarity analysis beyond pairwise steps.\n  - Report PSNR/SSIM reconstruction metrics alongside model utility.\n- Automate reporting\n  - Script that aggregates JSON/PT across rounds and emits plots + a succinct experiment brief into `reports/`.\n\n## Methods & Artifacts\n- Data & splits\n  - CIFAR‑100 with non‑IID partitioning via Dirichlet α=0.5 inside `src/fl_simulation/fed_avg.ipynb`.\n- Training\n  - Configurable optimizer (SGD/Adam), learning rate, local epochs, and client sampling; CUDA supported where available.\n- Telemetry & persistence\n  - Per‑client gradient norms, per‑layer norms, and loss captured; persisted as `{round}_meta.json` and `_tensors.pt` for time‑series and forensic analysis.\n- Attack analysis\n  - `src/attacks/quality_metrics.py` computes cosine similarity, L2 distance, directional alignment, gradient norm ratios, parameter‑wise correlation, and layer‑wise similarity.\n  - `src/attacks/run_attacks.py` loads the latest round tensors and produces a risk‑scored report + visualization to `reports/attacks/`.\n- Encryption (planned)\n  - `src/encryption/selective_encrypt.py` is the staging area for TenSEAL‑based selective encryption: layer subsets first, then broader coverage, measuring PSNR/SSIM, runtime, and convergence impact.\n\n## Grounding In The Literature\nThis work follows the taxonomy and defenses covered in “Security and Privacy in Federated Learning,” including:\n- Threat models: honest‑but‑curious servers/clients, untrusted aggregators, and collusion scenarios.\n- Attacks: gradient inversion/reconstruction and membership inference as practical probes of leakage.\n- Defenses: differential privacy, secure aggregation, and homomorphic encryption; analysis of their trade‑offs (utility, cost, composability).\n\nThose concepts provide the structure for evaluating both the privacy risk and the mitigation overheads observed in this project’s experiments.\n\n## Acknowledgments\nSpecial thanks to **Yan Jiang** for collaborating closely throughout development, and to my **Capstone teammates** for their shared effort and discussions that shaped the project’s direction.","tech_tags":["Python","Federated Learning","Security","Encryption"],"created_at":"2025-10-30T05:35:48.326677+00:00"},{"id":"80b51708-efa4-4ab8-a97e-9a61ea3bdefc","title":"Bank Term Deposit Prediction with Neural Networks","description":"A deep learning model to predict customer term deposit subscriptions using banking and economic data. Achieved 90% accuracy with strong AUC performance, addressing class imbalance and campaign optimization.","full_description":"**Project Goal:** Predict which bank customers will subscribe to a term deposit using advanced machine learning, with a focus on real-world business impact and model interpretability.\n\n## 1. Data Overview & Preprocessing\n\n**Dataset:** 41,188 samples, 21 features (demographics, financials, campaign data). Target: `y` (term deposit subscription).\n\n**Sample Data:**\n```csv\n\"age\";\"job\";\"marital\";\"education\";\"default\";\"housing\";\"loan\";\"contact\";\"month\";\"day_of_week\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"emp.var.rate\";\"cons.price.idx\";\"cons.conf.idx\";\"euribor3m\";\"nr.employed\";\"y\"\n56;\"housemaid\";\"married\";\"basic.4y\";\"no\";\"no\";\"no\";\"telephone\";\"may\";\"mon\";261;1;999;0;\"nonexistent\";1.1;93.994;-36.4;4.857;5191;\"no\"\n57;\"services\";\"married\";\"high.school\";\"unknown\";\"no\";\"no\";\"telephone\";\"may\";\"mon\";149;1;999;0;\"nonexistent\";1.1;93.994;-36.4;4.857;5191;\"no\"\n... (see full dataset)\n```\n\n**Cleaning Steps:**\n- Removed duplicates\n- Replaced \"unknown\" in categorical columns with mode\n- Encoded categorical features (one-hot, cyclic for months)\n\n**Feature Table:**\n| Feature | Description |\n|---------|-------------|\n| age | Client age |\n| job | Job type |\n| marital | Marital status |\n| ... | ... |\n| y | Subscribed? (target) |\n\n---\n\n## 2. Exploratory Data Analysis\n\n**Numerical Features:**\n![Numerical Distributions](https://raw.githubusercontent.com/imaddde867/Bank-Term-Deposit-Prediction/main/screenshots/numerical_data_analysis.png)\n\n**Categorical Features:**\n![Numerical Distributions](https://raw.githubusercontent.com/imaddde867/Bank-Term-Deposit-Prediction/main/screenshots/categorical_data.png)\n\n**Correlation Matrix:**\n![Correlation Matrix](https://raw.githubusercontent.com/imaddde867/Bank-Term-Deposit-Prediction/main/screenshots/correlations.png)\n\n**Feature Selection:**\n- Dropped highly correlated/redundant features (e.g., euribor3m, emp.var.rate, previous, pdays...etc)\n\n---\n\n## 3. Feature Engineering\n\n- Standardized/normalized numerical features\n- One-hot/cyclic encoding for categoricals\n- Feature importance via Random Forest\n\n---\n\n## 4. Model Development: Artificial Neural Network (ANN)\n\n**Why ANN?**\nArtificial Neural Networks (ANNs) are powerful for capturing complex, non-linear relationships in high-dimensional data. Here, an ANN outperformed tree-based models in AUC and generalization.\n\n**Architecture:**\n```python\nmodel = Sequential([\n    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n    BatchNormalization(),\n    Dropout(0.3),\n    Dense(64, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.2),\n    Dense(32, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.2),\n    Dense(1, activation='sigmoid')\n])\n```\n\n**Training:**\n- Early stopping and learning rate reduction to prevent overfitting\n- 150 epochs, batch size 64, validation split\n\n**Training Curves:**\n![Training Curves](https://raw.githubusercontent.com/imaddde867/Bank-Term-Deposit-Prediction/main/screenshots/initial_classification_results.png)\n\n---\n\n## 5. Model Validation & Optimization\n\n**Cross-Validation:**\n5-fold cross-validation for robust accuracy estimation:\n```python\n# Set up cross-validation\nkfold = KFold(n_splits=5, shuffle=True, random_state=42)\ncv_scores = []\n\n# Manual cross-validation loop\nfor train_idx, val_idx in kfold.split(X_scaled):\n    # Split data\n    X_train_cv, X_val_cv = X_scaled.iloc[train_idx], X_scaled.iloc[val_idx]\n    y_train_cv, y_val_cv = y.iloc[train_idx], y.iloc[val_idx]\n    \n    # Build model\n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(128, activation='relu', input_shape=(X_scaled.shape[1],)),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(32, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    \n    # Compile\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(0.001),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    # Train\n    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n    history = model.fit(\n        X_train_cv, y_train_cv,\n        epochs=50,\n        batch_size=64,\n        validation_data=(X_val_cv, y_val_cv),\n        callbacks=[early_stopping],\n        verbose=0\n    )\n    \n    # Evaluate\n    _, accuracy = model.evaluate(X_val_cv, y_val_cv, verbose=0)\n    cv_scores.append(accuracy)\n```\n**Result:** CV Accuracy ≈ 0.8992 (±0.0022)\n\n**Hyperparameter Tuning:**\nGrid search over batch size, learning rate, dropout, optimizer. \nBest: batch_size=32, lr=0.001, dropout=0.2, optimizer='rmsprop'.\n```\nParams: {'batch_size': 32, 'learning_rate': 0.001, 'dropout_rate': 0.2, 'optimizer': 'adam', 'accuracy': 0.9023476839065552}\n/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n...\n\nBest parameters: {'batch_size': 32, 'learning_rate': 0.001, 'dropout_rate': 0.2, 'optimizer': 'rmsprop', 'accuracy': 0.9024488925933838}\n```\nFinal Best parameters: batch_size=32, lr=0.001, dropout=0.2, optimizer='rmsprop'.\n\n---\n\n## 6. Final Evaluation & Results\n\n**Test Set Performance:**\n- Final Test Accuracy: 0.8961\n- ROC AUC Score: 0.7777\n\n**Classification Report:**\n\n```text\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.90      0.99      0.94      3636\n           1       0.76      0.16      0.27       482\n\n    accuracy                           0.90      4118\n   macro avg       0.83      0.58      0.61      4118\nweighted avg       0.88      0.90      0.87      4118\n```\n\n**Confusion Matrix:**\n```text\n[[3611   25]\n [ 403   79]]\n```\n\n\n**ROC Curve:**\n![ROC Curve](https://raw.githubusercontent.com/imaddde867/Bank-Term-Deposit-Prediction/main/screenshots/final_ROC_curve.png)\n\n---\n\n## 7. Insights & Recommendations\n\n**Key Insights:**\n- Model is highly precise but recall for subscribers is low (class imbalance)\n- ANN is robust for complex, high-dimensional data\n\n**Business Recommendations:**\n- Use class weighting or threshold tuning to improve recall\n- Consider ensemble with tree-based models for further gains\n\n---\n\n## Conclusion\n\nThis project demonstrates the power of ANNs for bank marketing prediction, with a rigorous workflow from cleaning to hyperparameter tuning. The approach is generalizable to other imbalanced, high-dimensional business problems.","tech_tags":["Machine Learning","Deep Learning","TensorFlow","Binary Classification","Data Analysis","Model Evaluation"],"created_at":"2025-07-16T16:51:08.100635+00:00"},{"id":"5cf746e6-934f-400d-b51b-62e0daa4a183","title":"imadlab.me - Personal Portfolio & Technical Blog Platform","description":"A React-TypeScript portfolio website featuring real-time integrations, secure admin portal, and dynamic content management. Built with modern web technologies and optimized for performance, SEO, and user experience.","full_description":"\u003Cdiv align=\"center\">\n  \u003Cimg src=\"https://raw.githubusercontent.com/imaddde867/imadlab/refs/heads/master/doc/Hero_section.png\"  \n       alt=\"imadlab hero section screenshot\"  \n       width=\"800\"  \n       style=\"max-width:100%;border-radius:16px;box-shadow:0 2px 16px rgba(0,0,0,0.10);margin-bottom:12px;\" />\n\u003C/div>\n\n## imadlab — My Personal Site & Builder’s Lab\n\nI built **imadlab** as a production-grade portfolio and content platform—part showcase, part playground. It’s a React + Supabase app with real-time bits, an admin surface for publishing, and a fast, polished UI. Blogs and projects are prerendered for SEO, but the site stays fully interactive.\n\n**What’s inside:**\n- **Projects** with live demos, code, and short case studies  \n- **Technical blog** with code blocks, math, and clean URLs  \n- **Live integrations** (Spotify Now Playing, newsletter, real-time toasts)\n\n---\n\n## Highlights\n\n|           Feature         |   Description                                                                 |\n| :------------------------: | :----------------------------------------------------------------------------- |\n|   **Interactive Gallery**  | Filter, search, and explore projects with live demos and GitHub links.        |\n|    **Rich Blog Engine**    | Markdown + GFM, math, syntax highlighting, and SEO-ready metadata.            |\n| **Real-Time Integrations** | Spotify now-playing, newsletter signup, Sonner toasts for notifications.      |\n|    **Secure Admin CMS**    | Role-based Supabase Auth, full CRUD, session management.                      |\n|    **Performance & UX**    | 95+ Lighthouse, code-splitting, lazy loading, and GSAP/Framer Motion polish.  |\n\n---\n\n## Admin Portal in Action\n\n\u003Cp align=\"center\">\n  \u003Cvideo\n    src=\"/imad_lab_demo.mp4\"\n    controls\n    preload=\"metadata\"\n    playsinline\n  >\n    Your browser does not support the video tag.\n  \u003C/video>\n\u003C/p>\n\n---\n\n## Tech Stack\n\n\u003Cdiv align=\"center\">\n\n| Layer            | Tools & Libraries                                     |\n| ---------------- | ----------------------------------------------------- |\n| **Frontend**     | React 18 · TypeScript · Vite · Tailwind CSS           |\n| **UI Kit**       | shadcn/ui · Radix UI · Lucide Icons · Framer Motion   |\n| **State & Data** | TanStack Query · React Hook Form · Zod validation     |\n| **Backend**      | Supabase (Postgres · Auth · Storage · Edge Functions) |\n| **Integrations** | Spotify Web API · Newsletter API · GSAP animations    |\n| **CI/CD**        | GitHub Actions · Automated sitemap generation         |\n| **Hosting**      | Vercel · Netlify · GitHub Pages                       |\n\n\u003C/div>\n\n---\n\n## Architecture Overview\n\n```\nimadlab/\n├── public/                   # Static assets, favicons & meta files\n├── src/\n│   ├── components/           # Reusable UI components\n│   │   └── ui/               # shadcn/ui component library\n│   ├── hooks/                # Custom React hooks\n│   ├── integrations/         # Third‑party service integrations\n│   │   └── supabase/         # Supabase client and types\n│   ├── lib/                  # Utilities & helper functions\n│   ├── pages/                # Route components with lazy loading\n│   ├── App.tsx               # Root component with routing\n│   └── main.tsx              # Entry point with providers\n├── supabase/                 # DB schema & migrations\n├── scripts/                  # Build scripts & Spotify token generator\n├── .github/                  # CI/CD workflows\n├── package.json              # Scripts & dependencies\n└── tailwind.config.ts        # Design system configuration\n```\n\n---\n\n## Getting Started\n\nSpin up your own **imadlab**:\n\n### 1) Prerequisites\n\n```bash\n# Node & npm\n> node --version   # v18+\n> npm --version\n# Supabase CLI\n> supabase --version\n```\n\n### 2) Clone & Install\n\n```bash\ngit clone https://github.com/imaddde867/imadlab.git\ncd imadlab\nnpm install\n```\n\n### 3) Configure Supabase\n\n```bash\nsupabase init\nsupabase link --project-ref \u003CYOUR_PROJECT_REF>\nsupabase db push\nsupabase gen types typescript \\\n  --project-id \"\u003CYOUR_PROJECT_ID>\" \\\n  --schema public > src/integrations/supabase/types.ts\n```\n\n> **Tip:** Store env vars as `VITE_SUPABASE_URL`, `VITE_SUPABASE_ANON_KEY`, etc.\n\n### 4) Run & Build\n\n```bash\n# Dev server\nnpm run dev      # → http://localhost:8080\n\n# Production\nnpm run build    # Includes sitemap generation\nnpm run preview\n```\n\n---\n\n## Design & UX\n\n- **Animated interactions:** ClickSpark effects, GSAP layers, ambient backgrounds  \n- **Accessible & responsive:** Radix primitives, keyboard-friendly navigation  \n- **Fast by default:** React.lazy, optimized media, stable skeletons and fallbacks\n\n---\n\n## Implementation Notes\n\n- **Error handling:** Global `ErrorBoundary` + route-level Suspense fallbacks  \n- **Type-safe data:** End-to-end TypeScript with generated Supabase types  \n- **SEO:** `react-helmet-async`, automated sitemap/feed, prerendered `/projects` & `/blogs`  \n- **State:** TanStack Query for server state; lightweight context for app state  \n- **CI/CD:** GitHub Actions builds and deploys; static assets shipped to `gh-pages`\n\n---\n\n## What’s Next\n\n- **Analytics dashboard** for traffic and engagement  \n- **Automated backups** for Supabase  \n- **Dark mode** toggle  \n- **Lighthouse CI** for continuous performance checks\n\n--- \n\n*imadlab is my home base on the web—equal parts portfolio, lab notebook, and shipping lane. The code and content ops are built to scale as I do.*","tech_tags":["React","TypeScript","Tailwind CSS","Supabase","Vite","Spotify API","Formspree","PostgreSQL"],"created_at":"2025-07-16T15:28:37.47409+00:00"},{"id":"51d8de9b-5876-4eda-ac5b-3411814bda84","title":"ClearBox - Secure Messaging Platform","description":"ClearBox is a full-stack secure messaging platform featuring real-time encrypted communication, group chat, and GDPR compliance, built with FastAPI, React, and MQTT.","full_description":"## Project Overview\n\nClearBox is a secure, scalable messaging platform I built to make private, GDPR-compliant communication effortless. It’s a full-stack app that ties together real-time messaging, practical encryption, and a clean architecture—showcasing my work in systems design, security, and data engineering.\n\n\u003Cp align=\"center\">\n  \u003Cimg src=\"https://raw.githubusercontent.com/imaddde867/ClearBox/main/clearbox/frontend/logo/vector/default-monochrome-white.svg\" alt=\"ClearBox Logo\" width=\"400\"/>\n\u003C/p>\n\n## Highlights\n\n* **End-to-end platform**: Real-time chat with a full auth → store → deliver pipeline\n* **Privacy by design**: GDPR-aligned data handling across the stack\n* **Scalable architecture**: Layered design ready for thousands of concurrent users\n* **Zero-cost deployment**: Netlify, Render, Supabase, HiveMQ (free tiers)\n* **Clear docs**: Architecture diagrams and database schema included\n\n## Visual Preview\n\n### User Interface Screenshots\n\n**Login Interface** \u003Cimg src=\"https://raw.githubusercontent.com/imaddde867/ClearBox/main/clearbox/frontend/public/screenshots/login.png\" alt=\"Login Screen\" width=\"600\"/>\n\n**Real-time Chat Interface** \u003Cimg src=\"https://raw.githubusercontent.com/imaddde867/ClearBox/main/clearbox/frontend/public/screenshots/chat.png\" alt=\"Chat Interface\" width=\"600\"/>\n\n**Contact Management System** \u003Cimg src=\"https://raw.githubusercontent.com/imaddde867/ClearBox/main/clearbox/frontend/public/screenshots/contacts.png\" alt=\"Contacts Management\" width=\"600\"/>\n\n## Technical Architecture & Data Engineering\n\n### Database Design\n\n\u003Cimg src=\"https://raw.githubusercontent.com/imaddde867/ClearBox/main/clearbox/docs/database.png\" alt=\"Database Schema\" width=\"700\"/>\n\nRelational schema (6 tables), designed for integrity and scale:\n\n* **users**: auth, profiles, status; passwords hashed with **bcrypt**\n* **conversations**: 1:1 and groups with ownership\n* **conversation_members**: roles/permissions (admin, member)\n* **messages**: encrypted content, delivery + read receipts\n* **user_contacts**: relationships (pending/accepted/blocked)\n* **notifications**: real-time alerts with references\n\nOptimized with proper indexing and 1-to-many / many-to-many relationships via `conversation_members`.\n\n### System Architecture\n\n\u003Cimg src=\"https://raw.githubusercontent.com/imaddde867/ClearBox/main/clearbox/docs/diagram.png\" alt=\"System Architecture\" width=\"700\"/>\n\n* **Client**: Responsive web/mobile\n* **Edge**: **Nginx** for HTTPS, static assets, routing\n* **App**: React (Context API), **FastAPI** (auth, messages, users)\n* **Messaging**: **MQTT** (Mosquitto/HiveMQ) for delivery, presence, typing\n* **Data**: **PostgreSQL** (prod), **SQLite** (dev) via **SQLAlchemy**\n\n### Data Flows\n\n1. **Auth**: Login → backend validate → JWT issued → stored client-side → protected routes verify\n2. **Messaging**: Send → backend persist → publish to MQTT → online clients update; offline clients sync on reconnect\n3. **Realtime**: Status changes + notifications broadcast via MQTT; subscribers update instantly\n\n## Core Features\n\n### Communication\n\n* Real-time messaging (WebSockets via **MQTT.js**)\n* Group chats with role-based permissions\n* Offline queueing & delivery\n* Read receipts & typing indicators\n* Emoji support (`emoji-picker-react`)\n\n### Security\n\n* **Fernet** symmetric encryption (cryptography)\n* **JWT** auth with expiry/refresh\n* **bcrypt** password hashing with salt\n* Session and CORS hardening\n* Full **HTTPS** (TLS)\n\n### Privacy & Compliance\n\n* GDPR rights: access, deletion, minimization\n* Purpose-limited data collection\n* User-controlled account deletion & export\n* Audit logging for security monitoring\n\n## Technology Stack\n\n**Frontend**: React 18.2, Context API, Axios 1.8.4, MQTT.js 5.0.5, React Router 6.16, FontAwesome, emoji-picker-react\n**Backend**: FastAPI 0.104, SQLAlchemy 2.0.22, PostgreSQL/SQLite, `python-jose` (JWT) 3.3.0, Pydantic 2.4.2, Cryptography 41.0.4, paho-mqtt 2.1.0\n**Infra & DevOps**: Mosquitto MQTT, Nginx, Gunicorn/Uvicorn, Netlify, Render, Supabase, HiveMQ Cloud\n\n## Challenges & What I Shipped\n\n**SQLite → PostgreSQL migration**\nBuilt `migrations/migrate_to_postgres.py` to: back up SQLite, map types, enforce FKs, transfer data, and validate integrity—so local dev stays lightweight while prod runs on PostgreSQL.\n\n**Reliable realtime delivery**\nSolved reconnects, topic design, ordering, and offline delivery using MQTT QoS with sub-second latency.\n\n**Security without friction**\nBalanced Fernet encryption, hardened JWT flows, properly tuned bcrypt, and strict CORS—aligned with OWASP guidance.\n\n## Deployment Strategy\n\n* **Frontend**: Netlify (`netlify.toml`)\n* **Backend**: Render (`render.yaml`)\n* **Database**: Supabase (PostgreSQL)\n* **MQTT**: HiveMQ Cloud (WebSocket)\n\nProduction-ready on free tiers, with sane defaults for reliability and security.\n\n## Performance\n\n* **Message delivery**: ~120 ms avg\n* **DB queries**: \u003C10 ms avg with indexing\n* **API responses**: \u003C100 ms for standard ops\n* **Initial load**: \u003C1.5 s; mobile payload \u003C1 MB\n\n## What I Learned\n\n* Building real-time systems with MQTT/WebSockets\n* Practical encryption & hardened authentication\n* Relational modeling and performance tuning\n* Cohesive full-stack integration\n* Clean, low-cost cloud deployment\n\n## Development Setup\n\n**Prerequisites**\n\n* Python 3.8+, Node.js 14+, PostgreSQL/SQLite\n* MQTT broker (Mosquitto recommended)\n* Modern browser with WebSocket support\n\n**Quick Start**\n\n```bash\n# Clone and setup backend\ngit clone https://github.com/imaddde867/ClearBox.git\ncd ClearBox/backend\npython -m venv venv && source venv/bin/activate\npip install -r requirements.txt\n\n# Setup frontend\ncd ../frontend\nnpm install && npm start\n```\n\n---\n\n*End-to-end source, docs, and deployment guides live in the repo.*\n\n**Project Type**: Full-stack Web App | **Duration**: 3 months | **Status**: Production-ready","tech_tags":["React","FastAPI","PostgreSQL","MQTT","WebSockets","JWT","Encryption","Docker","Nginx"],"created_at":"2025-07-07T15:59:10.79479+00:00"},{"id":"1139086b-79f9-44a0-8f81-145dcc137b74","title":"NAVICAST Maritime Intelligence","description":"Real-time maritime traffic analysis and AI predictive routing","full_description":"I built NAVICAST as a challenge from my professor, Tommi Tuomola, who’s passionate about maritime technologies and robust data engineering systems. The idea was simple: stream live AIS vessel data, predict ship trajectories, and serve it all through clean APIs on an interactive map. This project became my hands-on exploration of real-time data pipelines, geospatial visualization, and applied machine learning.\n\n\u003Cp align=\"center\">\n  \u003Cimg src=\"https://raw.githubusercontent.com/imaddde867/NaviCast/main/static/NAVICAST-logo/logo-white.svg\" alt=\"NAVICAST Logo\" width=\"500\"/>\n\u003C/p>\n\n\n## What it does\n\n- Streams live AIS from Digitraffic (Baltic Sea) over MQTT (TLS)\n- Stores normalized snapshots in PostgreSQL with raw JSONB\n- Predicts 30‑minute positions using a trained Random Forest model (with a dead‑reckoning fallback)\n- Exposes a FastAPI layer for vessels, details, downloads, and health\n- Visualizes everything on a Leaflet map with filters, status badges, and prediction overlays\n\n\u003Cp align=\"center\">\n  \u003Cvideo\n    src=\"/dashboard.mp4\"\n    controls\n    preload=\"metadata\"\n    playsinline\n  >\n    Your browser does not support the video tag.\n  \u003C/video>\n\u003C/p>\n\n## How I built it\n\n1) Data ingestion (mqtt_client.py)\n- WebSocket MQTT client with batching (10 messages) and backoff reconnects\n- Field validation and sane defaults for SOG/COG/heading; JSON payloads persisted\n- Primary key on (vessel_id, timestamp) to avoid duplicates; 24‑hour rolling cleanup\n\n2) Storage model (schema.sql)\n- raw_ais_data: latest positions + raw JSONB for flexibility\n- predictions: one row per vessel (updated), plus a unique guard for timestamped predictions\n\n3) Prediction service (prediction_service.py)\n- Loads `vessel_prediction_model.pkl` if present; otherwise uses dead reckoning\n- Runs every 5 minutes and predicts 30 minutes ahead\n- Validates bounds (Baltic window) and outliers; writes upserts; prunes old rows\n\n4) API (api_server.py)\n- Endpoints: `/vessels`, `/vessels/{mmsi}`, `/vessels/download`, `/health`\n- MMSI→country mapping (MID), vessel type/status decoding, optional time filters\n- Returns safe, typed payloads and omits invalid predictions\n\n5) Frontend (static/index.html)\n- Leaflet map with live markers, direction indicators, and predicted paths\n- Filters for All / Moving / Stationary / Predictable (has API prediction)\n- Dark/light mode, compact control panel, CSV/JSON data export\n\n## Model and results\n\nTraining data: 363,899 position records from the Baltic Sea. I compared simple baselines against a Random Forest regressor predicting delta‑lat/delta‑lon for a 30‑minute horizon.\n\nHighlights:\n- Random Forest: mean distance error ≈ 0.154 km, median ≈ 0.011 km\n- Baselines (linear/polynomial, XGBoost) trail in distance error\n- If the model file is missing, the system gracefully falls back to dead reckoning\n\n\u003Cp align=\"center\">\n  \u003Cimg src=\"https://raw.githubusercontent.com/imaddde867/NaviCast/main/static/accuracy.png\" alt=\"Prediction Accuracy Visualization\" width=\"720\"/>\n\u003C/p>\n\n## System architecture\n\n\u003Cp align=\"center\">\n  \u003Cimg src=\"https://raw.githubusercontent.com/imaddde867/NaviCast/main/static/diagram.png\" alt=\"System Architecture Diagram\" width=\"800\"/>\n\u003C/p>\n\nData flow in short:\n- MQTT → Postgres (validated, deduped, JSONB kept)\n- Scheduled predictions → Postgres (upserted, validated)\n- FastAPI → map + exports\n\n## Decisions that mattered\n\n- Keep raw AIS as JSONB: future‑proofs the schema while indexing the fields I care about now.\n- Predict deltas, not absolutes: simpler target space and better generalization across headings.\n- Validate hard at the edges: clip SOG/COG/heading, enforce geographic bounds, skip low‑signal cases.\n- Make failure harmless: if ML fails or is absent, use deterministic dead reckoning so the UI never breaks.\n\n## What was tricky (and how I handled it)\n\n- Noisy AIS fields: normalized ranges and wrote conservative defaults before storage.\n- Duplicate/late data: primary keys + distinct‑on queries in the API.\n- Map performance: minimal DOM work, reuse markers, toggle layers instead of re‑creating.\n- Time windows: sensible defaults on the API (last hour) with explicit ISO overrides.\n\n## Tech stack\n\n- Python, FastAPI, Uvicorn\n- PostgreSQL (JSONB, indexes)\n- Paho‑MQTT (WebSockets + TLS)\n- scikit‑learn, pandas, joblib\n- Leaflet.js (client‑side)\n\n## Run it locally\n\nPrereqs: PostgreSQL 13+, Python 3.9+\n\n```bash\npsql -c \"CREATE DATABASE ais_project;\"\npsql -d ais_project -f schema.sql\npip install -r requirements.txt\n./start_navicast.sh\n# dashboard → http://localhost:8000\n```\n\nTip: set `NAVICAST_DB_*` env vars and `NAVICAST_MODEL_PATH` to point at your DB/model.\n\n## Data and privacy\n\n- Uses public AIS broadcasts; no personal data is collected\n- Raw positions retained ~24h by default; predictions shorter\n- Extensive rotating logs for observability\n\n## What’s next\n\n- Weather/context features into the model\n- Alerting (course deviation, proximity)\n- Historical playback and analytics\n\n—\n\nThis project is a hands‑on snapshot of how I like to build: real‑time first, practical ML, simple interfaces, and resilience by design.\n","tech_tags":["Python","FastAPI","PostgreSQL","Machine Learning","MQTT","Leaflet.js","Real-time Processing"],"created_at":"2025-07-06T10:16:11.425063+00:00"},{"id":"ea66518d-ced2-4d09-b84c-63f57eefd644","title":"Spotify AI Music Recommendation","description":"An AI music recommender using PCA, K-means clustering, and Spotify audio features, with a Flask API and modern frontend interface.","full_description":"This project is an advanced music recommendation engine powered by machine learning, designed to deliver highly personalized song suggestions based on audio feature analysis and clustering techniques. Built with a production-ready architecture, it combines a robust backend, a responsive frontend, and sophisticated algorithms to provide a seamless user experience.\n\n## Project Overview\n\nThe system analyzes over 1.1 million Spotify tracks, using Principal Component Analysis (PCA) and K-means clustering to group songs by audio characteristics. It offers two recommendation modes: one driven by Spotify's API for real-time song data and another using a preprocessed dataset for offline capabilities. The result is a scalable, reliable application that delivers tailored music recommendations with sub-second response times.\n\n## Key Features\n\n### Machine Learning Core\n- **Dimensionality Reduction**: PCA implementation preserves 91.99% of data variance, optimizing audio feature processing while reducing noise.\n- **Clustering Algorithm**: K-means groups songs into 35 optimized clusters based on audio similarity patterns.\n- **Feature Engineering**: Analyzes 11 core audio features plus engineered composite metrics like energy-to-acousticness ratios and vocal character analysis.\n- **Similarity Matching**: Uses cosine similarity within clusters for precise song recommendations with comprehensive error handling.\n\n### Web Application\n- **Flask REST API**: Scalable backend with comprehensive error handling and health monitoring.\n- **Responsive Interface**: Modern, accessible frontend with dark mode support and keyboard shortcuts.\n- **Real-Time Processing**: Generates recommendations in under 500ms using pre-trained models.\n- **Multi-level Fallback System**: Ensures uninterrupted service with four distinct recommendation strategies.\n\n### Data Pipeline\n- **Large-scale Dataset**: 1,159,764 Spotify tracks with detailed audio features.\n- **Robust Preprocessing**: Handles missing values, outliers, and feature scaling with validation checks.\n- **Model Persistence**: Optimized model serialization for efficient production deployment.\n\n## Technical Architecture\n\n### System Components\n- **Machine Learning Engine**: Implements PCA, K-means, and similarity calculations (src/recommendation_engine.py).\n- **Web Application**: Flask-based API server and responsive frontend (src/web/app.py and templates).\n- **Data Pipeline**: Feature engineering and model training workflow (notebooks/main.ipynb).\n- **Model Artifacts**: Pre-trained models and preprocessed data (src/models/).\n\n### Audio Features\nThe system processes the following Spotify audio features:\n\n| Feature           | Description                          | Processing         |\n|-------------------|--------------------------------------|--------------------|\n| Danceability      | Suitability for dancing              | Normalized (0-1)   |\n| Energy            | Intensity and activity               | Normalized (0-1)   |\n| Valence           | Musical positivity                   | Normalized (0-1)   |\n| Acousticness      | Acoustic vs. electronic confidence   | Normalized (0-1)   |\n| Instrumentalness  | Likelihood of vocal absence          | Normalized (0-1)   |\n| Liveness          | Presence of live audience            | Normalized (0-1)   |\n| Speechiness       | Presence of spoken words             | Normalized (0-1)   |\n| Tempo             | Speed in BPM                         | MinMax scaled      |\n| Loudness          | Volume in dB                         | Standard scaled    |\n| Key               | Musical key                          | One-hot encoded    |\n| Mode              | Major or minor scale                 | One-hot encoded    |\n\n## Screenshots\n\n### User Interface\n![Application Interface](https://raw.githubusercontent.com/imaddde867/spotify-clusters/main/docs/interface.png)\n\n### Search Functionality\n![Search Interface](https://raw.githubusercontent.com/imaddde867/spotify-clusters/main/docs/search.png)\n\n### Recommendation Results\n![Search Results](https://raw.githubusercontent.com/imaddde867/spotify-clusters/main/docs/result.png)\n\n## How It Works\n\n1. **Input Processing**: User provides a song name and artist, validated and normalized.\n2. **Spotify API Integration**: Fetches audio features for the input song with retry logic and caching.\n3. **Feature Preprocessing**: Scales and transforms features using trained models (StandardScaler, MinMaxScaler).\n4. **Cluster Assignment**: K-means predicts optimal cluster placement for the song.\n5. **Similarity Computation**: Calculates cosine similarity within the assigned cluster for precise matching.\n6. **Result Ranking**: Orders recommendations by similarity with distance-based metrics.\n7. **Fallback Handling**: Implements four levels of fallback strategies when API is unavailable:\n   - **Primary**: Spotify API + ML pipeline\n   - **Secondary**: Dataset fuzzy matching + clustering\n   - **Tertiary**: Random sampling from similar genres\n   - **Emergency**: Popular track recommendations\n\n## Performance Metrics\n\n| Metric                  | Value         | Description                              |\n|-------------------------|---------------|------------------------------------------|\n| Variance Preserved      | 91.99%        | PCA dimensionality reduction efficiency  |\n| Cluster Count           | 35            | Optimized K-means configuration          |\n| Dataset Size            | 1,159,764     | Total tracks analyzed                    |\n| Response Time           | \u003C500ms        | Average recommendation generation        |\n| Memory Usage            | ~2GB          | Model loading and operation requirements |\n\n## Setup Instructions\n\n### Prerequisites\n- Python 3.8+\n- Spotify Developer Account (for API access)\n- 4GB+ RAM (for model loading)\n\n### Steps\n1. **Clone the Repository**:\n   ```bash\n   git clone https://github.com/imaddde867/spotify-clusters.git\n   cd spotify-clusters\n   ```\n2. **Set Up Virtual Environment**:\n   ```bash\n   python -m venv venv\n   source venv/bin/activate  # Windows: venv\\Scripts\\activate\n   ```\n3. **Install Dependencies**:\n   ```bash\n   pip install -r requirements.txt\n   ```\n4. **Configure Spotify API**:\n   - Copy .env.example to .env\n   - Add your Spotify Client ID and Client Secret to .env\n\n### Running the Application\n- **Development**:\n   ```bash\n   python src/web/app.py\n   # Or use convenience script\n   ./run.sh  # Unix/Mac\n   run.bat   # Windows\n   ```\n- **Production**:\n   ```bash\n   gunicorn --bind 0.0.0.0:5000 --workers 4 src.web.app:app\n   ```\n\nAccess the app at `http://localhost:5001` (development) or `http://localhost:5000` (production).\n\n## API Documentation\n\n- **GET /**: Serves the main application interface.\n- **POST /recommend**: Generates music recommendations.\n  - Example Request:\n    ```json\n    {\n      \"song_name\": \"Bohemian Rhapsody\",\n      \"artist_name\": \"Queen\",\n      \"playlist_size\": 10\n    }\n    ```\n  - Response includes track names, artists, genres, and popularity scores.\n- **GET /api/popular-examples**: Provides sample songs for the interface.\n- **GET /health**: System health check endpoint with component status.\n\n## Development Insights\n\n### Technical Challenges Addressed\n- **Memory Optimization**: Implemented efficient data loading and processing for the 1.1M+ track dataset.\n- **API Resilience**: Created a robust caching system to reduce Spotify API calls and handle rate limits.\n- **Error Recovery**: Designed comprehensive try/except blocks with multiple fallback mechanisms.\n- **Frontend Accessibility**: Implemented keyboard shortcuts, screen reader support, and responsive design.\n\n### Future Enhancements\n- Integrate a database backend for faster data retrieval and user preferences.\n- Add user playlist analysis for personalized clustering and recommendations.\n- Enhance frontend with interactive audio feature visualizations.\n- Implement collaborative filtering to complement content-based recommendations.\n\n## Technologies Used\n- **Backend**: Python 3.8+, Flask 2.0+, scikit-learn, pandas, numpy, spotipy\n- **Frontend**: HTML5, CSS3, Vanilla JavaScript with accessibility features\n- **Deployment**: Gunicorn-ready, Docker-compatible\n- **Data**: Spotify API, 1.1M+ track dataset with 11 core audio features\n\n## Project Status\n- **Status**: Production-Ready\n- **Maintenance**: Active Development\n- **Performance**: Sub-second recommendation generation\n\nThis project showcases my expertise in machine learning, web development, and API integration, delivering a practical and engaging solution for music discovery that combines sophisticated algorithms with a polished user experience.","tech_tags":["Python","Machine Learning","Flask","Spotify API","PCA","KMeans"],"created_at":"2025-07-06T10:15:07.421174+00:00"}];</script>
</body>
</html>
