<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Meta tags dynamically injected by <Seo /> component via react-helmet-async -->
    <!-- Static fallbacks only for crawlers that don't execute JS -->
    <title>Vehicle Detection and Stylization Benchmark (GAN-CNN) | Imadlab | Research Engineer &amp; Internal CTO</title>
    <meta name="description" content="Computer vision benchmark from labeled detection data to deployable models with reproducible training artifacts and model export." />
    <!-- prerender-seo:start -->
    <link rel="canonical" href="https://imadlab.me/projects/5aae3db6-ac22-487a-9822-bbffc27833e9" />
    <meta property="og:title" content="Vehicle Detection and Stylization Benchmark (GAN-CNN) | Imadlab | Research Engineer &amp; Internal CTO" />
    <meta property="og:description" content="Computer vision benchmark from labeled detection data to deployable models with reproducible training artifacts and model export." />
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://imadlab.me/projects/5aae3db6-ac22-487a-9822-bbffc27833e9" />
    <meta property="og:image" content="https://raw.githubusercontent.com/imaddde867/GAN-CNN/main/results/milestone4/stylized_07504.jpg" />
    <meta property="og:image:alt" content="Vehicle Detection and Stylization Benchmark (GAN-CNN)" />
    <meta property="og:locale" content="en_US" />
    <meta property="og:site_name" content="Imadlab" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:site" content="@imadlab" />
    <meta name="twitter:creator" content="@imadlab" />
    <meta name="twitter:title" content="Vehicle Detection and Stylization Benchmark (GAN-CNN) | Imadlab | Research Engineer &amp; Internal CTO" />
    <meta name="twitter:description" content="Computer vision benchmark from labeled detection data to deployable models with reproducible training artifacts and model export." />
    <meta name="twitter:image" content="https://raw.githubusercontent.com/imaddde867/GAN-CNN/main/results/milestone4/stylized_07504.jpg" />
    <meta name="twitter:image:alt" content="Vehicle Detection and Stylization Benchmark (GAN-CNN)" />
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"SoftwareApplication","name":"Vehicle Detection and Stylization Benchmark (GAN-CNN)","description":"Computer vision benchmark from labeled detection data to deployable models with reproducible training artifacts and model export.","url":"https://imadlab.me/projects/5aae3db6-ac22-487a-9822-bbffc27833e9","image":"https://raw.githubusercontent.com/imaddde867/GAN-CNN/main/results/milestone4/stylized_07504.jpg","codeRepository":"https://github.com/imaddde867/GAN-CNN","sameAs":["https://github.com/imaddde867/GAN-CNN"],"datePublished":"2025-12-24T19:03:27.022547+00:00","dateModified":"2026-02-09T12:18:27.145+00:00","author":{"@type":"Person","name":"Imad Eddine El Mouss","url":"https://imadlab.me/about"}}</script>
    <!-- prerender-seo:end -->

    <!-- Favicon and Theme Color -->
    <link rel="icon" href="/favicon.ico" sizes="any">
    <link rel="apple-touch-icon" href="/apple-touch-icon.png">
    <meta name="theme-color" content="#000000" />

    <!-- Preload hero image for faster LCP on home route -->
    <link rel="preload" as="image" href="/images/hero-moon.avif" type="image/avif" />

    <!-- Font Preconnect for Performance -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    
    <!-- Load fonts with font-display: swap for better performance -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&family=JetBrains+Mono:wght@300;400;500;600;700&display=swap" rel="stylesheet" media="print" onload="this.media='all'">
    <noscript>
      <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&family=JetBrains+Mono:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    </noscript>
    
    <!-- DNS prefetch for Supabase and Cloudflare Analytics -->
    <link rel="dns-prefetch" href="https://mpkgugcasxpanhrkpkhs.supabase.co">
    <link rel="preconnect" href="https://mpkgugcasxpanhrkpkhs.supabase.co" crossorigin>
    <link rel="dns-prefetch" href="https://static.cloudflareinsights.com">
    <link rel="preconnect" href="https://static.cloudflareinsights.com" crossorigin>
    
    <!-- RSS/JSON Feeds -->
    <link rel="alternate" type="application/rss+xml" title="Imadlab Blog RSS Feed" href="/feed.xml" />
    <link rel="alternate" type="application/feed+json" title="Imadlab Blog JSON Feed" href="/feed.json" />
    <meta name="referrer" content="strict-origin-when-cross-origin" />

    <!-- Structured Data -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "WebSite",
      "url": "https://imadlab.me",
      "name": "Imadlab",
      "description": "Applied research and engineering work by Imad Eddine El Mouss on multimodal industrial AI, procedural knowledge extraction, and deployable systems.",
      "publisher": {
        "@type": "Person",
        "name": "Imad Eddine El Mouss",
        "url": "https://imadlab.me/about",
        "sameAs": [
          "https://github.com/imaddde867",
          "https://www.linkedin.com/in/imad-eddine-e-986741262"
        ]
      },
      "potentialAction": {
        "@type": "SearchAction",
        "target": "https://duckduckgo.com/?q=site%3Aimadlab.me+{search_term_string}",
        "query-input": "required name=search_term_string"
      }
    }
    </script>
    <script type="module" crossorigin src="/assets/js/index-B1IGmRtD.js"></script>
    <link rel="stylesheet" crossorigin href="/assets/index-9eB0Q-OK.css">
  </head>

  <body>
    <h1 style="position: absolute; width: 1px; height: 1px; padding: 0; margin: -1px; overflow: hidden; clip: rect(0, 0, 0, 0); border: 0;">Imadlab | Research Engineer & Internal CTO</h1>
    <div id="root">
<main data-prerender="true" class="prerender-shell">
  <article class="prerender-article">
    <p class="prerender-meta text-sm text-white/60">December 24, 2025</p>
    <h1 class="text-3xl font-bold mb-4">Vehicle Detection and Stylization Benchmark (GAN-CNN)</h1>
    <p class="prerender-tags">Tech: computer-vision, object-detection, model-optimization, yolov5, tensorflow</p>
    <div class="prerender-image"><img src="https://raw.githubusercontent.com/imaddde867/GAN-CNN/main/results/milestone4/stylized_07504.jpg" alt="Vehicle Detection and Stylization Benchmark (GAN-CNN)" loading="lazy" decoding="async" /></div>
    <p class="prerender-summary leading-relaxed">This repository documents a four-stage workflow that mixes data engineering, classical model diagnostics, and deployment-oriented training:

1) Dataset curation and annotation in YOLO TXT format (6 vehicle classes).
2) A custom CNN (TensorFlow/Keras) trained for a high-signal question: &quot;car vs other&quot;. The notebook shows the diagnosis that the baseline model was dominated by class imbalance, then applies class weig...</p>
    <p class="prerender-meta mt-4">Source: <a class="prerender-link inline" href="https://github.com/imaddde867/GAN-CNN" rel="noopener">View repository</a></p>
    <a class="prerender-link mt-6 inline-flex" href="/projects/5aae3db6-ac22-487a-9822-bbffc27833e9">Continue exploring</a>
  </article>
</main>
</div>
    
  <script>window.__PRERENDERED_DATA__ = window.__PRERENDERED_DATA__ || {}; window.__PRERENDERED_DATA__["project:5aae3db6-ac22-487a-9822-bbffc27833e9"] = {"id":"5aae3db6-ac22-487a-9822-bbffc27833e9","title":"Vehicle Detection and Stylization Benchmark (GAN-CNN)","description":"Computer vision benchmark from labeled detection data to deployable models with reproducible training artifacts and model export.","full_description":"This repository documents a four-stage workflow that mixes data engineering, classical model diagnostics, and deployment-oriented training:\n\n1) Dataset curation and annotation in YOLO TXT format (6 vehicle classes).\n2) A custom CNN (TensorFlow/Keras) trained for a high-signal question: \"car vs other\". The notebook shows the diagnosis that the baseline model was dominated by class imbalance, then applies class weighting, Dropout, L2 regularization, and training callbacks to recover minority-class performance.\n3) Multi-class object detection by fine-tuning Ultralytics YOLOv5s with reproducible run logs (`args.yaml`, `results.csv`, plots) and export artifacts (PyTorch weights plus Core ML package for on-device inference).\n4) A lightweight GAN-style stylization stage (\"VividNeonTexture\") that consumes YOLO crops and writes curated, portfolio-ready composites to `results/milestone4/`.\n\nKey quantitative outcomes from committed artifacts:\n- CNN (car vs other): 82.7% -> 91.1% accuracy; car precision 50.8% -> 88.9%; car recall 41.0% -> 56.4%.\n- YOLOv5 (6-class detection): best mAP50-95 reaches 0.90684 with precision 0.95036 and recall 0.94483 (50 epochs, Apple Silicon `device=mps`, AMP, disk cache).\n\n## Pipeline or Architecture\n1. Prepare images + YOLO TXT annotations (class_id, x_center, y_center, width, height)\n2. Build a binary dataset (car = 1, other vehicles = 0) and train a Keras CNN (`best_model.h5`)\n3. Generate `data.yaml` and fine-tune YOLOv5s; track runs under `runs/detect/train_optimized/`\n4. Export the best detector checkpoint and Core ML package (`runs/detect/train_optimized/weights/`)\n5. Run YOLO on images, crop detections, and stylize with VividNeonTexture; save composites to `results/milestone4/`\n\n## Dataset/Training Snapshot\n| Item | Value |\n| --- | --- |\n| Labeled images (YOLO) | 3,000 (`dataset/images/`) |\n| Label files (YOLO) | 3,000 (`dataset/annotations/`) |\n| Vehicle classes | 6 (`car`, `threewheel`, `bus`, `truck`, `motorbike`, `van`) |\n| Total bounding boxes | 3,835 (avg 1.28 boxes/image) |\n| Boxes per class_id | 0: 662, 1: 709, 2: 588, 3: 629, 4: 699, 5: 548 |\n| CNN input / batch | 224x224 RGB, batch 32 |\n| CNN split (binary) | train: 1,718 (cars 345), val: 731 (cars 156) |\n| YOLO config | 50 epochs, batch 16, imgsz 416, lr0 0.01, warmup 3.0, cache=disk, amp=true, device=mps |\n\n## Evaluation/Tracking Snapshot\n| Model | Metric | Value | Source artifact |\n| --- | --- | --- | --- |\n| CNN (baseline) | Accuracy | 82.7% | `main.ipynb` |\n| CNN (baseline) | Car precision / recall | 50.8% / 41.0% | `main.ipynb` |\n| CNN (optimized) | Accuracy | 91.1% | `main.ipynb` |\n| CNN (optimized) | Car precision / recall | 88.9% / 56.4% | `main.ipynb` |\n| YOLOv5 (best epoch) | Precision / recall | 0.95036 / 0.94483 | `runs/detect/train_optimized/results.csv` |\n| YOLOv5 (best epoch) | mAP50 / mAP50-95 | 0.97804 / 0.90684 | `runs/detect/train_optimized/results.csv` |\n| YOLOv5 (training time) | Total time | 8,137.55 s (~2h 15m) | `runs/detect/train_optimized/results.csv` |\n\n## Visual Evidence and Artifacts\n![YOLO predictions on validation batch](https://raw.githubusercontent.com/imaddde867/GAN-CNN/main/runs/detect/train_optimized/val_batch0_pred.jpg)\n\n![YOLO training curves](https://raw.githubusercontent.com/imaddde867/GAN-CNN/main/runs/detect/train_optimized/results.png)\n\n![Normalized confusion matrix](https://raw.githubusercontent.com/imaddde867/GAN-CNN/main/runs/detect/train_optimized/confusion_matrix_normalized.png)\n\n![Precision-Recall curve](https://raw.githubusercontent.com/imaddde867/GAN-CNN/main/runs/detect/train_optimized/BoxPR_curve.png)\n\n![VividNeonTexture sample](https://raw.githubusercontent.com/imaddde867/GAN-CNN/main/results/milestone4/stylized_car366.jpg)\n\n## Engineering Highlights\n- Reproducible experiment tracking: YOLO run metadata (`args.yaml`), per-epoch metrics (`results.csv`), and plots committed under `runs/detect/train_optimized/`\n- Class-imbalance diagnosis and remediation for CNN: explicit baseline vs optimized deltas with class weighting (4.96x), Dropout 0.4, L2=0.01, and callbacks (EarlyStopping, ReduceLROnPlateau)\n- Deployment artifacts included: `best_model.h5` for Keras inference and `runs/detect/train_optimized/weights/best.mlpackage` for Core ML\n- Hardware-aware training configuration: Apple Silicon MPS + AMP + disk cache for faster iterations\n- Modular pipeline reuse: YOLO crops become inputs to the stylization stage, producing curated visuals in `results/milestone4/`\n\n## Try It\n```bash\npython -m venv .venv && source .venv/bin/activate\npip install -U ultralytics tensorflow torch torchvision opencv-python matplotlib jupyter\nyolo detect predict model=runs/detect/train_optimized/weights/best.pt source=dataset/images imgsz=416 save=true\n```\n","tech_tags":["computer-vision","object-detection","model-optimization","yolov5","tensorflow"],"created_at":"2025-12-24T19:03:27.022547+00:00","updated_at":"2026-02-09T12:18:27.145+00:00","image_url":"https://raw.githubusercontent.com/imaddde867/GAN-CNN/main/results/milestone4/stylized_07504.jpg","repo_url":"https://github.com/imaddde867/GAN-CNN","demo_url":null,"featured":false};</script>
</body>
</html>
