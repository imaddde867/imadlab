{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "Imadlab Blog",
  "home_page_url": "https://imadlab.me",
  "feed_url": "https://imadlab.me/feed.json",
  "description": "Latest writing from Imadlab on data engineering, AI, and machine learning.",
  "items": [
    {
      "id": "https://imadlab.me/blogs/1st-llm",
      "url": "https://imadlab.me/blogs/1st-llm",
      "title": "How I Built My First Small Local LLM From Scratch",
      "summary": "A journey of curiosity, countless late nights, and surprisingly many cups of coffee",
      "tags": [
        "Machine-Learning",
        "LLM",
        "NLP",
        "DeepLearning",
        "Transformer"
      ],
      "date_published": "2025-07-11T21:07:09.397Z",
      "date_modified": "2025-07-11T21:07:09.538Z",
      "content_text": "The Spark That Started It All I'll be honest with you—six months ago, I thought building a language model was something only PhD researchers at big tech companies could do. I mean, we're talking about neural networks that can understand and generate human language, right? That's got to be rocket science. But then I stumbled across a YouTube video of someone training a tiny GPT model on Shakespeare's works, and something just clicked. \"What if I could build my own?\" I thought. Not something that would compete with ChatGPT or Claude, but something mine —something I could understand from the ground up. Spoiler alert: it was harder than I expected, but also way more rewarding than I imagined. Why I Decided to Go Local (And Small) Before diving into the technical stuff, let me tell you why I chose to build a small, local model instead of just fine-tuning an existing one. First, privacy . I wanted something that would run entirely on my machine, no data leaving my computer. Second, understanding . I'm the kind of person who needs to know how things work under the hood. And third, constraints breed creativity . With my M4 MacBook Pro and its 16GB of unified memory, I had to get creative about architecture and training. No fancy GPU here—just the neural engine and whatever PyTorch could squeeze out of Metal Performance Shaders. The Technical Journey Step 1: Understanding the Basics I started with the fundamentals. If you're thinking about doing this yourself, don't skip this part like I almost did. I spent two weeks just reading papers and tutorials: - The original \"Attention Is All You Need\" paper (read it three times before it clicked) - Andrej Karpathy's \"makemore\" series (absolute gold) - The nanoGPT repository Pro tip : Don't try to understand everything at once. I made notes in a simple text file, and looking back, some of my early notes make me laugh. \"Attention = somehow the model looks at different parts of the input\" was one of my profound insights. Step 2: Choosing My Architecture I went with a decoder-only transformer architecture, similar to GPT but much smaller. Here's what I settled on: - 6 layers (compared to GPT-3's 96) - 8 attention heads - 384 embedding dimensions - Vocabulary size: 10,000 tokens - Context window: 512 tokens Total parameters? About 10 million. Tiny by today's standards, but perfect for my laptop. Step 3: The Data Dilemma This was my first real challenge. What do you train a small model on? I considered several options: - Wikipedia dumps (too big, too varied) - Books (copyright issues) - My own writing (not enough data) I ended up creating a curated dataset mixing: - Public domain books from Project Gutenberg - Wikipedia articles on topics I cared about - Programming tutorials and documentation - Some Reddit discussions (carefully filtered) Final dataset: about 50MB of text. Small, but focused. Step 4: Implementation Reality Check I initially planned to write everything from scratch in pure Python. That lasted about two days. Here's what I actually ended up using: - PyTorch for the neural network (with MPS backend for M4 acceleration) - Hugging Face tokenizers for text preprocessing - Weights & Biases for experiment tracking - A lot of Stack Overflow for debugging Metal Performance Shaders issues The actual model implementation was about 200 lines of Python. Here's the surprising part: getting PyTorch to properly utilize the M4's neural engine took longer than writing the model itself. Apple's Metal Performance Shaders documentation became my bedtime reading. Step 5: Training Adventures My first training run was a disaster. The loss went to NaN after 100 steps, and I had no idea why. After some debugging (and discovering that MPS has some quirks with certain operations), I found out my learning rate was way too high and I needed to move some operations back to CPU. Training specs: - Batch size : 8 (memory constraints with 16GB shared between system and model) - Learning rate : 3e-4 (after much experimentation) - Training time : 2 days on M4 (surprisingly efficient!) - Final loss : 2.4 (not great, but not terrible) The M4 was actually fantastic for this kind of work. The unified memory architecture meant I could load larger datasets than I expected, and the neural engine handled the matrix operations beautifully once I got the MPS backend working properly. I trained three different versions, each time learning something new: 1. Version 1 : Overfit to the training data 2. Version 2 : Added dropout, but learning rate was still wrong 3. Version 3 : Finally got it right The Moment of Truth After two days of training version 3, I nervously typed my first prompt: \"The future of artificial intelligence\" The output was... underwhelming: The future of artificial intelligence is a complex and multifaceted topic that involves many different aspects of technology and society. In recent years, there has been... It was generic, but it was coherent . My little model was actually generating reasonable text! I may have done a small victory dance in my room. (The M4 stayed remarkably cool throughout this whole process, which was a nice bonus.) What I Learned (The Hard Way) Technical Lessons 1. Learning rate scheduling matters more than I thought . I spent hours tweaking the architecture when the real problem was my learning rate decay. 2. Data quality beats data quantity . My 50MB of curated text worked better than the 500MB of random internet text I tried first. 3. Regularization is crucial . Without proper dropout and weight decay, my model would memorize the training data instead of learning patterns. Personal Lessons 1. Start smaller than you think . My first attempt had 50 million parameters. My successful model had 10 million. 2. Document everything . I wish I'd kept better notes about what worked and what didn't. Future me would thank past me. 3. The community is amazing . I got help from strangers on Reddit, Discord, and Twitter. The ML community really wants to help newcomers. Performance and Limitations Let's be real about what my little model can and can't do: What it's good at: - Writing coherent paragraphs on familiar topics - Completing sentences in a reasonable way - Following basic instruction patterns What it struggles with: - Complex reasoning - Staying on topic for long passages - Anything requiring real-world knowledge - Math (it once told me 2+2=5, very confidently) Lessons for Anyone Thinking About This If you're considering building your own LLM, here's my honest advice: Do it if: - You want to understand how these models really work - You enjoy debugging and experimentation - You have a specific use case in mind - You learn better by doing than reading Don't expect: - To build the next ChatGPT - It to be easy or quick - Perfect results on your first try - To save money compared to using APIs What's Next? I'm already planning version 4. I want to experiment with: - Mixture of Experts architecture - Better tokenization strategies - Instruction tuning on my own dataset - Quantization to make it even more efficient But honestly? The biggest win isn't the model itself—it's the understanding I gained. Every time I use ChatGPT or Claude now, I have a much better appreciation for what's happening under the hood. Final Thoughts Building my own LLM was like learning to cook by growing your own vegetables. Sure, you can buy better results at the store, but there's something magical about the process. Every bug I fixed, every hyperparameter I tuned, every coherent sentence my model generated—it all felt like a small victory. If you're curious about AI and have some programming experience, I'd encourage you to try it. Not because you'll build something revolutionary, but because you'll understand something revolutionary in a completely new way. And who knows? Maybe your small model will surprise you, just like mine surprised me."
    }
  ]
}